{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO2O2JKu0wpwfcfxzvqBRtt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guilhermelaviola/IntegrativePracticeInDataScience/blob/main/Class14.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Disruptive Solutions**\n",
        "Disruptive solutions leverage new technologies or reconfigured processes to significantly transform markets by improving efficiency, quality, and user experience while lowering costs. Innovation management emphasizes the strategic use of resources to generate value. Pivotal drivers of these innovations include Data Science, Business Intelligence, and Machine Learning, with Data Science focused on large data analysis and Big Data solutions like Hadoop and Spark enhancing data processing. Machine Learning automates learning from historical data, showcased by applications like chatbots that improve customer interactions. While challenges exist, including costs and resistance to change, structured implementation is crucial for success, highlighting the ongoing impact of these innovations in areas like Machine Learning and IoT on future developments."
      ],
      "metadata": {
        "id": "_fmIh8k5dDif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing all the necessary libraries:\n",
        "import pandas as pd\n",
        "from pyspark.sql import SparkSession\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import pandas as pd\n",
        "import random\n",
        "import time"
      ],
      "metadata": {
        "id": "0l6ZLRc-LTha"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Analyzing Large Data (Pandas + Simple Aggregation)**"
      ],
      "metadata": {
        "id": "5XBYc8uGLTvl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating a large dataset of customer interactions:\n",
        "data = {\n",
        "    'customer_id': range(1, 11),\n",
        "    'interaction_time': [12, 5, 3, 9, 15, 7, 8, 10, 4, 6],\n",
        "    'satisfaction_score': [4, 5, 3, 4, 5, 2, 4, 5, 3, 4]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Basic Data Science analysis:\n",
        "avg_time = df['interaction_time'].mean()\n",
        "avg_satisfaction = df['satisfaction_score'].mean()\n",
        "\n",
        "print('Average Handling Time:', avg_time)\n",
        "print('Average Satisfaction Score:', avg_satisfaction)"
      ],
      "metadata": {
        "id": "671Cu_BcLbBl",
        "outputId": "a59ca1e8-e996-43de-f6b1-796007aed8e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Handling Time: 7.9\n",
            "Average Satisfaction Score: 3.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Big Data Processing concept**"
      ],
      "metadata": {
        "id": "cX49GpgRLXZw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of how Spark would process a much larger dataset distributed across clusters:\n",
        "spark = SparkSession.builder.appName('BigDataExample').getOrCreate()\n",
        "\n",
        "# Loading large dataset:\n",
        "df = spark.read.csv('customer_logs.csv', header=True, inferSchema=True)\n",
        "\n",
        "# Performing distributed computation:\n",
        "result = df.groupBy('event_type').count()\n",
        "\n",
        "result.show()"
      ],
      "metadata": {
        "id": "rIKqGWsjLjGQ",
        "outputId": "fa2d363e-0dfb-4119-d6e4-e8dbdbb60c66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AnalysisException",
          "evalue": "[PATH_NOT_FOUND] Path does not exist: file:/content/customer_logs.csv.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2034786749.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load large dataset (e.g., log files)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'customer_logs.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minferSchema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Perform distributed computation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mcsv\u001b[0;34m(self, path, schema, sep, encoding, quote, escape, comment, header, inferSchema, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, nullValue, nanValue, positiveInf, negativeInf, dateFormat, timestampFormat, maxColumns, maxCharsPerColumn, maxMalformedLogPerPartition, mode, columnNameOfCorruptRecord, multiLine, charToEscapeQuoteEscaping, samplingRatio, enforceSchema, emptyValue, locale, lineSep, pathGlobFilter, recursiveFileLookup, modifiedBefore, modifiedAfter, unescapedQuoteHandling)\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoSeq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRDD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAnalysisException\u001b[0m: [PATH_NOT_FOUND] Path does not exist: file:/content/customer_logs.csv."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Machine Learning example**"
      ],
      "metadata": {
        "id": "C1j_LG0JLXeS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training a Model to Predict Satisfaction:\n",
        "# Example dataset:\n",
        "df = pd.DataFrame({\n",
        "    'interaction_time': [12, 5, 3, 9, 15, 7, 8, 10, 4, 6],\n",
        "    'issues_resolved': [2, 1, 1, 2, 3, 1, 2, 3, 1, 2],\n",
        "    'satisfaction_score': [4, 5, 3, 4, 5, 2, 4, 5, 3, 4]\n",
        "})\n",
        "\n",
        "X = df[['interaction_time', 'issues_resolved']]\n",
        "y = df['satisfaction_score']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "print('Predictions:', predictions)\n",
        "print('MSE:', mean_squared_error(y_test, predictions))"
      ],
      "metadata": {
        "id": "MQ_kq9HEL2QQ",
        "outputId": "9befe2a9-971b-4041-a06a-705e7cf3c406",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions: [4.02862986 4.2392638  3.92842536]\n",
            "MSE: 1.4327878633272135\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Chatbot Example with Machine Learning-Driven Interaction**"
      ],
      "metadata": {
        "id": "_QIJSBMpLXh_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple chatbot that uses keyword matching. It is not a real ML model, but can be used to illustrate.\n",
        "def simple_chatbot(user_input):\n",
        "    user_input = user_input.lower()\n",
        "\n",
        "    if 'problem' in user_input:\n",
        "        return 'I am sorry to hear that. Can you describe the issue?'\n",
        "    elif 'help' in user_input:\n",
        "        return 'Sure! How can I support you today?'\n",
        "    elif 'thanks' in user_input:\n",
        "        return 'You are welcome!'\n",
        "    else:\n",
        "        return 'I am here to assist you with your request.'\n",
        "\n",
        "# Example interaction:\n",
        "print(simple_chatbot('I need help with my account'))"
      ],
      "metadata": {
        "id": "ncbYg2oWME2t",
        "outputId": "0aef685c-6d14-44a2-cdf8-cb9aef413754",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sure! How can I support you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **IoT + Analytics example**"
      ],
      "metadata": {
        "id": "YmXIlIsULXqP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training a model to predict satisfaction:\n",
        "def read_sensor():\n",
        "    # Simulated IoT temperature sensor:\n",
        "    return 20 + random.random() * 5\n",
        "\n",
        "for _ in range(5):\n",
        "    print('Temperature reading:', read_sensor())\n",
        "    time.sleep(1)"
      ],
      "metadata": {
        "id": "hNhy5nqYMNY8",
        "outputId": "e2175d38-818e-4d84-eae1-eb4be281d92c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Temperature reading: 24.733400262748535\n",
            "Temperature reading: 23.769699737841414\n",
            "Temperature reading: 20.926567252512978\n",
            "Temperature reading: 22.948347180002404\n",
            "Temperature reading: 20.340772716586116\n"
          ]
        }
      ]
    }
  ]
}